## AI Speak‚ÄëThink‚ÄëPlay‚ÄØTool 0.1.0  
*A lightweight utility for interacting with an LLM via audio (or a text prompt) and receiving spoken responses.*

---

### What It Does
- **Transcribes** spoken input (audio file) with a local Speech‚Äëto‚ÄëText (STT) model (privacy‚Äëfirst for your voice).  
- Sends the transcription to a Gemini LLM.  
- Returns the LLM‚Äôs answer as **speech** using Text‚Äëto‚ÄëSpeech (TTS).  

> Ideal for polishing pronunciation in foreign languages, but flexible enough for any audio‚Äëdriven workflow.

---

### Prerequisites  

| Item | How to obtain |
|------|----------------|
| **Vertex‚ÄØAI API key** | Create a Vertex‚ÄØAI project in Google Cloud, enable the API, then copy the key into a `.env` file as `VERTEX_AI_API_KEY`. |
| **OAuth2 service‚Äëaccount JSON** | In the same Google Cloud project, enable the **Text‚Äëto‚ÄëSpeech** API, create a service‚Äëaccount key, and store the file path in `.env` as `SECRET_JSON_FILEPATH`. |

> **Note:** This is a learning / testing project. You are fully responsible for any costs (e.g., token usage, Google Cloud quotas) incurred by running the code.

---

### Installation  


# Clone the repo (if you haven‚Äôt already)

```bash
git clone https://github.com/ArchBober/AI-Speak-Think-Play-Tool.git
cd AI-Speak-Think-Play-Tool
```
# Install dependencies with uv (recommended)
```bash
uv venv
source .venv/bin/activate # on windows can be different
uv sync   # reads pyproject.toml
```

### Running the Tool  

```bash
uv run main.py [options] <input-audio-filepath>
uv run main.py [options] --prompt "<your prompt text>"
```
#### Options  

| Flag | Description |
|------|-------------|
| `--help` | Show the help text (this document). |
| `--prompt "<text>"` | Bypass STT and feed your own prompt directly to the LLM. |
| `--verbose` | Enable detailed logging and extra CLI output. |

**Examples**

```bash
# Normal usage ‚Äì record from microphone or load an audio file
uv run main.py "audiofile.mp3"

# Supply a custom prompt instead of transcribing audio
uv run main.py --prompt "Explain quantum entanglement in plain English."

# Get verbose output for debugging
uv run main.py "audiofile.mp3" --verbose
```
### How It Works (high‚Äëlevel)

1. **Capture audio** (for now only file).  
2. **Local STT** ‚Üí produces a text transcript.  
3. **Send transcript** to a Gemini model (via Vertex‚ÄØAI).  
4. **Receive LLM response** (text).  
5. **TTS** ‚Üí synthesize the response as audio and play it back.

---

## Configuration Constants

| Variable | Default Value | Description |
|----------|---------------|-------------|
| `OUTPUT_AUDIO_FILEPATH` | `"response.mp3"` | Path (relative or absolute) where the synthesized speech audio will be saved after the TTS step. |
| `LANGUAGE` | `"en-US"` | BCP‚Äë47 language tag used by the STT and TTS services (e.g., `en-US`, `es-ES`, `fr-FR`). |
| `LANGUAGE_LVL` | `"B1"` | Target proficiency level for the learner (A1‚ÄëB2 range). This value is injected into the LLM prompt to adapt the difficulty of the conversation. |
| `SPEAKING_RATE` | `1.2` | Speed multiplier for the generated voice. `1.0` is the default; acceptable range is roughly `0.5` (slow) ‚Üí `2.0` (fast). |
| `STT_MODEL` | `"turbo"` | Identifier of the Whisper‚Äëstyle speech‚Äëto‚Äëtext model. Options include:<br>‚Ä¢ `tiny`‚ÄØ(‚âà‚ÄØ1‚ÄØGB VRAM)<br>‚Ä¢ `base`‚ÄØ(‚âà‚ÄØ1‚ÄØGB VRAM)<br>‚Ä¢ `small`‚ÄØ(‚âà‚ÄØ2‚ÄØGB VRAM)<br>‚Ä¢ `medium`‚ÄØ(‚âà‚ÄØ5‚ÄØGB VRAM)<br>‚Ä¢ `large`‚ÄØ(‚âà‚ÄØ10‚ÄØGB VRAM)<br>‚Ä¢ `turbo`‚ÄØ(‚âà‚ÄØ6‚ÄØGB VRAM, fastest inference). |
| `LLM_MODEL` | `"gemini-2.0-flash"` | The generative‚ÄëAI model used for the dialogue. Gemini‚Äë2.0‚ÄëFlash offers a good balance of speed and quality for conversational tasks. |
| `TTS_MODEL` | `"gemini-2.5-flash-lite-preview-tts"` | The text‚Äëto‚Äëspeech model that produces the audio response. The *lite* preview is optimized for lower latency and cost. |
| `TTS_VOICE` | `"Enceladus"` | Named voice preset supplied by the TTS model. Different voices have distinct timbres and accents; choose the one that best fits a language‚Äëteacher persona. |
| `LLM_PROMPT` | *(see below)* | System prompt fed to the LLM. It sets the role (‚Äúlanguage teacher‚Äù), tone (simple vocabulary, short answers), student proficiency (`{LANGUAGE_LVL}`), and name (`Mark Spencer`). The prompt also encourages ending replies with a question to keep the conversation flowing. |
| `TTS_PROMPT` | `"As a teacher of en_US language talk with calm and polite voice."` | Optional instruction for the TTS engine to shape prosody (calm, polite) and reinforce the teaching persona. |
| ~~`MAX_CHARS`~~ | ~~`10000`~~ | `NOT IMPLEMENTED!` ~~Upper limit on the number of characters that can be sent to the LLM in a single request. Prevents oversized payloads that could exceed API limits.~~ |
| `TTS_AUDIO_TOKEN_PRICE` | `10` | Cost (in your chosen currency unit) per **audio token** generated by the TTS model. Useful for budgeting and cost‚Äëtracking scripts. Must be adjusted by user (check pricing page for each model) |
| `TTS_TEXT_TOKEN_PRICE` | `0.5` | Cost per **text token** processed by the TTS model (the input text length). Must be adjusted by user (check pricing page for each model) |
| `LLM_INPUT_TOKEN_PRICE` | `0.15` | Cost per **input token** sent to the LLM. Must be adjusted by user (check pricing page for each model) |
| `LLM_OUTPUT_TOKEN_PRICE` | `0.6` | Cost per **output token** returned by the LLM. Must be adjusted by user (check pricing page for each model) |

### Example of the `LLM_PROMPT` and `TTS_PROMPT`

```python
LLM_PROMPT = f"""
You are {LANGUAGE} teacher that help with basic difficulties of learning that language. Your main goal is to talk to student and use not too many hard words. Students are expected to be on level A1 up to B2 in that language. Your today student is expected to be on {LANGUAGE_LVL} language profficiency. Your name is Mark Spencer but tell your name only when asked. Also try to keep responses short and straight to the point. If possible try to end sentences with questions for student to keep conversation.
"""

TTS_PROMPT=f"""As a teacher of {LANGUAGE} language talk with calm and polite voice."""
```
---

### Sources worth peeking

| Topic | Resource | URL |
|-------|----------|-----|
| **Google Vertex AI Overview** | Official product page | https://cloud.google.com/vertex-ai |
| **Google Vertex AI Model Garden** | Catalog of pre‚Äëtrained models (including Gemini, PaLM, Imagen, etc.) | https://cloud.google.com/model-garden?hl=en|
| **Gemini Models on Vertex AI** | Details on Gemini family, versions, pricing, and usage limits | https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models |
| **Text‚Äëto‚ÄëSpeech (TTS) API** | Documentation for Google Cloud TTS, supported voices & formats | https://cloud.google.com/text-to-speech/docs |
| **Speech‚Äëto‚ÄëText (STT) API** | Docs for streaming and batch speech recognition | https://cloud.google.com/speech-to-text/docs |
| **Authentication (Service Accounts & OAuth2)** | How to create and use service‚Äëaccount keys for Vertex AI | https://cloud.google.com/docs/authentication/production |
| **Quota & Billing for Vertex AI** | Information on token usage, request limits, and cost estimation | https://cloud.google.com/vertex-ai/pricing |
| **Vertex AI Samples & Tutorials** | End‚Äëto‚Äëend notebooks and code snippets for common use‚Äëcases | https://github.com/GoogleCloudPlatform/vertex-ai-samples |
| **Google Generative AI Playground** (interactive demo of Gemini models) | Quick way to test prompts and see model capabilities | https://makersuite.google.com/app/apikey |
| **Security & Compliance** | Data protection, encryption, and compliance certifications for Vertex AI | https://cloud.google.com/security/compliance |


### Disclaimer  

- This repository is provided **as‚Äëis** for experimentation and learning.  
- The author assumes **no liability** for misuse, unexpected costs, or service restrictions arising from running the code.  
- By using or modifying the tool you accept full responsibility for any consequences (e.g., high token consumption, hitting Google Cloud limits, etc.).

--- 

Feel free to tweak the code, swap out the Gemini models, or integrate your own STT/TTS engines! üé§üó£Ô∏è‚ú®